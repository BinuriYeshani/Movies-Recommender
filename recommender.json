{"paragraphs":[{"text":"import java.io.File\nimport scala.io.Source\n\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\n","user":"anonymous","dateUpdated":"2020-03-04T03:17:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.rdd._\nimport org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\n"}]},"apps":[],"jobName":"paragraph_1583291039054_1906616","id":"20200304-030359_1623649215","dateCreated":"2020-03-04T03:03:59+0000","dateStarted":"2020-03-04T03:17:47+0000","dateFinished":"2020-03-04T03:17:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:172"},{"text":"\nval movieLensHomeDir = \"s3://aws-logs-559605839555-us-east-1/movieLens/\"\n\n\n\nval movies = sc.textFile(movieLensHomeDir + \"movies.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (movieId, movieName)\n  (fields(0).toInt, fields(1))\n}.collect.toMap\n\n\nval ratings = sc.textFile(movieLensHomeDir + \"ratings.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (timestamp % 10, Rating(userId, movieId, rating))\n  (fields(3).toLong % 10, Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble))\n}\n\n\n","user":"anonymous","dateUpdated":"2020-03-04T04:19:56+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"movieLensHomeDir: String = s3://aws-logs-559605839555-us-east-1/movieLens/\nmovies: scala.collection.immutable.Map[Int,String] = Map(2163 -> Attack of the Killer Tomatoes! (1980), 8607 -> Tokyo Godfathers (2003), 645 -> Nelly & Monsieur Arnaud (1995), 42900 -> Cul-de-sac (1966), 892 -> Twelfth Night (1996), 69 -> Friday (1995), 53550 -> Rescue Dawn (2006), 37830 -> Final Fantasy VII: Advent Children (2004), 5385 -> Last Waltz, The (1978), 5810 -> 8 Mile (2002), 7375 -> Prince & Me, The (2004), 5659 -> Rocking Horse Winner, The (1950), 2199 -> Phoenix (1998), 8062 -> Dahmer (2002), 3021 -> Funhouse, The (1981), 8536 -> Intended, The (2002), 5437 -> Manhattan Project, The (1986), 1322 -> Amityville 1992: It's About Time (1992), 1665 -> Bean (1997), 5509 -> Biggie and Tupac (2002), 5686 -> ..."}]},"apps":[],"jobName":"paragraph_1583291048995_1686601578","id":"20200304-030408_2118772948","dateCreated":"2020-03-04T03:04:08+0000","dateStarted":"2020-03-04T04:19:56+0000","dateFinished":"2020-03-04T04:20:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"text":"val numRatings = ratings.count\nval numUsers = ratings.map(_._2.user).distinct.count\nval numMovies = ratings.map(_._2.product).distinct.count\n\nprintln(\"Got \" + numRatings + \" ratings from \"\n  + numUsers + \" users on \" + numMovies + \" movies.\")\n  \n  ","user":"anonymous","dateUpdated":"2020-03-04T04:20:12+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583291877015_498216965","id":"20200304-031757_306269449","dateCreated":"2020-03-04T03:17:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:174","dateFinished":"2020-03-04T04:20:33+0000","dateStarted":"2020-03-04T04:20:12+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Got 10000054 ratings from 69878 users on 10677 movies.\nnumRatings: Long = 10000054\nnumUsers: Long = 69878\nnumMovies: Long = 10677\n"}]}},{"text":"val training = ratings.filter(x => x._1 < 6)\n  .values\n  .cache()\nval validation = ratings.filter(x => x._1 >= 6 && x._1 < 8)\n  .values\n  .cache()\nval test = ratings.filter(x => x._1 >= 8).values.cache()\n\nval numTraining = training.count()\nval numValidation = validation.count()\nval numTest = test.count()\n\nprintln(\"Training: \" + numTraining + \", validation: \" + numValidation + \", test: \" + numTest)","user":"anonymous","dateUpdated":"2020-03-04T04:20:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294706450_1278051044","id":"20200304-040506_882553005","dateCreated":"2020-03-04T04:05:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:175","dateFinished":"2020-03-04T04:21:10+0000","dateStarted":"2020-03-04T04:20:46+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Training: 6002473, validation: 1999675, test: 1997906\ntraining: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[45] at values at <console>:52\nvalidation: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[47] at values at <console>:55\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[49] at values at <console>:57\nnumTraining: Long = 6002473\nnumValidation: Long = 1999675\nnumTest: Long = 1997906\n"}]}},{"text":"/** Compute RMSE (Root Mean Squared Error). */\ndef computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\n    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\n    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating))\n    .join(data.map(x => ((x.user, x.product), x.rating))).values\n    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\n}","user":"anonymous","dateUpdated":"2020-03-04T04:21:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294703785_703125662","id":"20200304-040503_1840269480","dateCreated":"2020-03-04T04:05:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176","dateFinished":"2020-03-04T04:21:36+0000","dateStarted":"2020-03-04T04:21:36+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"computeRmse: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating], n: Long)Double\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294845465_-1089283923","id":"20200304-040725_496552026","dateCreated":"2020-03-04T04:07:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:719","text":"val ranks = List(8, 12)\nval lambdas = List(0.1, 10.0)\nval numIters = List(10, 20)\nvar bestModel: Option[MatrixFactorizationModel] = None\nvar bestValidationRmse = Double.MaxValue\nvar bestRank = 0\nvar bestLambda = -1.0\nvar bestNumIter = -1\nfor (rank <- ranks; lambda <- lambdas; numIter <- numIters) {\n  val model = ALS.train(training, rank, numIter, lambda)\n  val validationRmse = computeRmse(model, validation, numValidation)\n  println(\"RMSE (validation) = \" + validationRmse + \" for the model trained with rank = \" \n    + rank + \", lambda = \" + lambda + \", and numIter = \" + numIter + \".\")\n  if (validationRmse < bestValidationRmse) {\n    bestModel = Some(model)\n    bestValidationRmse = validationRmse\n    bestRank = rank\n    bestLambda = lambda\n    bestNumIter = numIter\n  }\n}","dateUpdated":"2020-03-04T04:22:02+0000","dateFinished":"2020-03-04T04:30:28+0000","dateStarted":"2020-03-04T04:22:02+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"RMSE (validation) = 0.8198584549047795 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 0.8190105679216674 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\nRMSE (validation) = 0.8223809132414455 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\nRMSE (validation) = 0.815337211135221 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\nRMSE (validation) = 3.667982949261605 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\nranks: List[Int] = List(8, 12)\nlambdas: List[Double] = List(0.1, 10.0)\nnumIters: List[Int] = List(10, 20)\nbestModel: Option[org.apache.spark.mllib.recommendation.MatrixFactorizationModel] = Some(org.apache.spark.mllib.recommendation.MatrixFactorizationModel@161cddcb)\nbestValidationRmse: Double = 0.815337211135221\nbestRank: Int = 12\nbestLambda: Double = 0.1\nbestNumIter: Int = 20\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294846295_-1078516263","id":"20200304-040726_809799293","dateCreated":"2020-03-04T04:07:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:791","text":"// evaluate the best model on the test set\nval testRmse = computeRmse(bestModel.get, test, numTest)\n\n//println(\"The best model was trained with rank = \" + bestRank + \" and lambda = \" + bestLambda + \", and numIter = \" + bestNumIter + \" and its RMSE on the test set is \" + testRmse + \".\")\n","dateUpdated":"2020-03-04T04:36:14+0000","dateFinished":"2020-03-04T04:36:28+0000","dateStarted":"2020-03-04T04:36:14+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"testRmse: Double = 0.8154706990456972\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294844430_-145057951","id":"20200304-040724_1994315270","dateCreated":"2020-03-04T04:07:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:647","text":"// create a naive baseline and compare it with the best model\nval meanRating = training.union(validation).map(_.rating).mean\nval baselineRmse = \n  math.sqrt(test.map(x => (meanRating - x.rating) * (meanRating - x.rating)).mean)\nval improvement = (baselineRmse - testRmse) / baselineRmse * 100\nprintln(\"The best model improves the baseline by \" + \"%1.2f\".format(improvement) + \"%.\")\n","dateUpdated":"2020-03-04T04:40:30+0000","dateFinished":"2020-03-04T04:40:30+0000","dateStarted":"2020-03-04T04:40:30+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"The best model improves the baseline by 23.05%.\nmeanRating: Double = 3.512362305720862\nbaselineRmse: Double = 1.0597828264660583\nimprovement: Double = 23.05303702976976\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294843100_-1424417078","id":"20200304-040723_837379554","dateCreated":"2020-03-04T04:07:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:575","text":"val candidates = sc.parallelize(movies.keys.toSeq)\nval recommendations = bestModel.get\n  .predict(candidates.map((100, _)))\n  .collect()\n  .sortBy(- _.rating)\n  .take(10)\n\nvar i = 1\nprintln(\"Movies recommended for you:\")\nrecommendations.foreach { r =>\n  println(\"%2d\".format(i) + \": \" + movies(r.product))\n  i += 1\n}","dateUpdated":"2020-03-04T04:40:34+0000","dateFinished":"2020-03-04T04:40:34+0000","dateStarted":"2020-03-04T04:40:34+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Movies recommended for you:\n 1: Eve and the Fire Horse (2005)\n 2: Maradona by Kusturica (2008)\n 3: Power of Nightmares: The Rise of the Politics of Fear, The (2004)\n 4: Shadows of Forgotten Ancestors (1964)\n 5: Low Life, The (1995)\n 6: Tunnel, The (Der Tunnel) (2001)\n 7: Pulp Fiction (1994)\n 8: Gonzo: The Life and Work of Dr. Hunter S. Thompson (2008)\n 9: Hospital (1970)\n10: Godfather, The (1972)\ncandidates: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[2584] at parallelize at <console>:55\nrecommendations: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(100,60983,4.284803242506937), Rating(100,61742,3.8259372372181053), Rating(100,53883,3.7578753510625846), Rating(100,42783,3.727724950601319), Rating(100,32090,3.664048538978891), Rating(100,27376,3.5691457512397817), Rating(100,296,3.553098724569817), Rating(100,60291,3.509192564480589), Rating(100,64280,3.504511740453336), Rating(100,858,3.5032501538407246))\ni: Int = 11\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294903760_-1542327501","id":"20200304-040823_295306035","dateCreated":"2020-03-04T04:08:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1151","text":"val moviesWithGenres = sc.textFile(movieLensHomeDir + \"movies.dat\").map { line =>\n  val fields = line.split(\"::\")\n  // format: (movieId, movieName, genre information)\n  (fields(0).toInt, fields(2))\n}.collect.toMap\n","dateUpdated":"2020-03-04T04:40:38+0000","dateFinished":"2020-03-04T04:40:39+0000","dateStarted":"2020-03-04T04:40:38+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"moviesWithGenres: scala.collection.immutable.Map[Int,String] = Map(2163 -> Comedy|Horror, 8607 -> Adventure|Animation|Drama, 645 -> Drama, 42900 -> Comedy|Crime|Drama|Thriller, 892 -> Comedy|Drama|Romance, 69 -> Comedy, 53550 -> Action|Adventure|Drama|War, 37830 -> Action|Adventure|Animation|Fantasy|Sci-Fi, 5385 -> Documentary, 5810 -> Drama, 7375 -> Comedy|Romance, 5659 -> Drama|Horror, 2199 -> Crime|Drama, 8062 -> Drama|Horror|Thriller, 3021 -> Horror, 8536 -> Drama|Thriller, 5437 -> Comedy|Thriller, 1322 -> Horror, 1665 -> Comedy, 5509 -> Documentary, 5686 -> Drama|Fantasy|War, 1036 -> Action|Crime|Thriller, 2822 -> Adventure|Romance, 7304 -> Animation|Comedy|Fantasy|Musical, 54999 -> Action|Adventure|Thriller, 2630 -> Drama, 6085 -> Comedy|Drama, 3873 -> Comedy|Western, 4188 -> Chil..."}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294902495_-116569868","id":"20200304-040822_2134770961","dateCreated":"2020-03-04T04:08:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1079","text":"val comedyMovies = moviesWithGenres.filter(_._2.matches(\".*Comedy.*\")).keys\nval candidates = sc.parallelize(comedyMovies.toSeq)\nval recommendations = bestModel.get\n  .predict(candidates.map((100, _)))\n  .collect()\n  .sortBy(- _.rating)\n  .take(5)\n\nvar i = 1\nprintln(\"Comedy Movies recommended for you:\")\nrecommendations.foreach { r =>\n  println(\"%2d\".format(i) + \": \" + movies(r.product))\n  i += 1\n}","dateUpdated":"2020-03-04T04:40:41+0000","dateFinished":"2020-03-04T04:40:42+0000","dateStarted":"2020-03-04T04:40:41+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Comedy Movies recommended for you:\n 1: Pulp Fiction (1994)\n 2: Yojimbo (1961)\n 3: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n 4: Mafioso (1962)\n 5: Fargo (1996)\ncomedyMovies: Iterable[Int] = Set(2163, 42900, 892, 69, 7375, 5437, 1665, 7304, 6085, 3873, 26413, 4201, 4447, 33004, 3962, 5422, 5469, 3944, 6387, 3883, 62851, 5116, 4094, 6167, 5088, 2889, 59858, 2295, 2306, 4571, 5857, 4464, 101, 2109, 1454, 4909, 2031, 5896, 59625, 2072, 8663, 4062, 3399, 54256, 33675, 6544, 4169, 4899, 53578, 6712, 55020, 5950, 3167, 31160, 4183, 909, 4290, 3477, 333, 3979, 2463, 3397, 49110, 3581, 8784, 3830, 6317, 518, 7990, 2499, 8843, 1083, 468, 54193, 5205, 6172, 4015, 26842, 234, 6690, 2331, 3566, 4728, 6954, 4877, 6014, 5582, 4992, 5131, 6374, 88, 50354, 47047, 32289, 352, 53993, 33145, 1855, 45722, 5454, 56176, 1211, 3990, 7888, 4714, 1158, 582, 762, 3072, 8883, 1005, 5141, 115, 6944, 3317, 5168, 4500, 65027, 7409, 5718, 34018, 37384, 46976, 276, 2622, 4402..."}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294902290_-94280800","id":"20200304-040822_2002099977","dateCreated":"2020-03-04T04:08:22+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1007","text":"// Save and load model\nbestModel.get.save(sc, \"s3://aws-logs-559605839555-us-east-1//movieLens/model/recommendation\")\nval sameModel = MatrixFactorizationModel.load(sc,  \"s3://emr.examples/movieLens/model/recommendation\")\n","dateUpdated":"2020-03-04T04:43:35+0000","dateFinished":"2020-03-04T04:43:35+0000","dateStarted":"2020-03-04T04:43:35+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory s3://aws-logs-559605839555-us-east-1/movieLens/model/recommendation/metadata already exists\n  at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n  at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)\n  at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)\n  at org.apache.spark.mllib.recommendation.MatrixFactorizationModel$SaveLoadV1_0$.save(MatrixFactorizationModel.scala:378)\n  at org.apache.spark.mllib.recommendation.MatrixFactorizationModel.save(MatrixFactorizationModel.scala:216)\n  ... 55 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294901970_-1686782400","id":"20200304-040821_564025087","dateCreated":"2020-03-04T04:08:21+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:935"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1583294900180_1917705158","id":"20200304-040820_976726887","dateCreated":"2020-03-04T04:08:20+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:863"}],"name":"recommender","id":"2F3XZ8NTV","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}